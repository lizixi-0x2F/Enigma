# Enigma å¯é€†åŠ¨æ€ç½®æ¢ç½‘ç»œ

> **æœ€æ–°ç‰ˆæœ¬**ï¼šåŸºäºåŒ»ç”Ÿå¤„æ–¹çš„è®­ç»ƒä¿®å¤ç³»ç»Ÿï¼Œæ”¯æŒ5å¼ 4090å¤šGPUå¹¶è¡Œè®­ç»ƒ
> 
> **ğŸƒ æœ€æ–°æ›´æ–° (2025-01-08)**ï¼šå®æ–½6æ¡åŒ»ç”Ÿå¤„æ–¹ä¿®å¤è®­ç»ƒé—®é¢˜ï¼Œä¿®å¤å¯¹é½é”™è¯¯

## é¡¹ç›®æ¦‚è¿°

Enigma æ˜¯ä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„å¯é€†åŠ¨æ€ç½®æ¢ç½‘ç»œï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºå†å²ä¸Šè‘—åçš„ Enigma å¯†ç æœºã€‚è¯¥ç½‘ç»œå…·æœ‰ä»¥ä¸‹ä¸»è¦ç‰¹ç‚¹ï¼š

1. **å®Œå…¨å¯é€†**ï¼šæ”¯æŒå‰å‘å’Œåå‘è®¡ç®—ï¼Œæ»¡è¶³ `f(fâ»Â¹(x)) = x` çš„ç‰¹æ€§ï¼Œé‡æ„è¯¯å·®ä½è‡³ 1e-6
2. **å†…å­˜é«˜æ•ˆ**ï¼šç›¸æ¯”ä¼ ç»Ÿç½‘ç»œå¯æ˜¾è‘—é™ä½å†…å­˜å ç”¨
3. **Glowé£æ ¼å¯é€†1Ã—1å·ç§¯**ï¼šæ›¿ä»£åŸå§‹Sinkhornç®—æ³•ï¼Œæä¾›æ›´é«˜çš„æ•°å€¼ç¨³å®šæ€§
4. **å¤šGPUå¹¶è¡Œè®­ç»ƒ**ï¼šæ”¯æŒ5å¼ 4090 GPUåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ•°æ®åˆ†ç‰‡å„å¸å…¶èŒ
5. **é˜²è¿‡æ‹Ÿåˆè®­ç»ƒ**ï¼šåŸºäº300M tokensæ•°æ®é›†çš„ä¸¥æ ¼æ­£åˆ™åŒ–é…ç½®
6. **æ‰©å±•åŠŸèƒ½**ï¼šæ”¯æŒå¯å¾®åˆ†ç½®æ¢å’Œç”Ÿæˆæ¨¡å‹åº”ç”¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### âš ï¸ æ•°æ®å‡†å¤‡è¦æ±‚

**é‡è¦æç¤º**: æœ¬é¡¹ç›®éœ€è¦ç”¨æˆ·è‡ªå¤‡ä»¥ä¸‹ç»„ä»¶ï¼š

1. **æ•°æ®é›†**: è‡ªè¡Œå‡†å¤‡ä¸­æ–‡æ–‡æœ¬æ•°æ®é›†ï¼Œå»ºè®®300M+ tokens
2. **BERTç¼–ç å™¨**: è‡ªè¡Œä¸‹è½½ä¸­æ–‡BERTé¢„è®­ç»ƒæ¨¡å‹
   - æ¨èï¼š`bert-base-chinese` æˆ– `chinese-bert-wwm-ext`
   - æ”¾ç½®è·¯å¾„ï¼š`bert-chinese-base/` ç›®å½•

### è®­ç»ƒæ¨¡å‹

```bash
# å¯åŠ¨é˜²è¿‡æ‹Ÿåˆè®­ç»ƒ (æ¨è)
python train.py

# å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
python monitor.py
```

### ğŸƒ åŒ»ç”Ÿå¤„æ–¹è®­ç»ƒé…ç½®

#### ğŸƒ å…­æ¡åŒ»ç”Ÿå¤„æ–¹å®æ–½ (2025-01-08)

åŸºäºæ¨¡å‹å›°æƒ‘åº¦é™åˆ°1ä½†è¾“å‡ºèƒ¡è¨€ä¹±è¯­çš„è¯Šæ–­ï¼Œå®æ–½ä»¥ä¸‹6æ¡"è¯æ–¹"ï¼š

| åºå· | è¯æ–¹å†…å®¹ | å®æ–½çŠ¶æ€ | å…·ä½“é…ç½® |
|------|----------|----------|----------|
| **1** | **é‡åˆ‡éªŒè¯é›†** | âœ… å·²å®æ–½ | 90%è®­ç»ƒ 10%éªŒè¯ï¼Œç¡®ä¿è¡Œçº§å»é‡æ— æ³„æ¼ |
| **2** | **ä¿®æ­£å¯¹é½** | âœ… å·²ä¿®å¤ | `inputs[0:n-1]` â†’ `logits` é¢„æµ‹ `targets[1:n]` |
| **3** | **ä¸¥æ ¼Mask** | âœ… å·²å®æ–½ | `reduction='sum'/mask.sum()` ç¡®ä¿åˆ†æ¯>0 |
| **4** | **æ—©åœé˜ˆå€¼** | âœ… å·²å®æ–½ | PPL>20è§¦å‘æ—©åœï¼Œæ¯500æ­¥è¯„ä¼° |
| **5** | **è½»è°ƒLR** | âœ… å·²å®æ–½ | 5e-4å­¦ä¹ ç‡ï¼Œcosine decayè°ƒåº¦ |
| **6** | **æ­£åˆ™åŠ å‘³** | âœ… å·²å®æ–½ | `dropout=0.1` + `weight_decay=0.01` |

```python
# ğŸƒ åŒ»ç”Ÿå¤„æ–¹è®­ç»ƒé…ç½®
config = {
    # ğŸƒ å¤„æ–¹1+4: é‡åˆ‡éªŒè¯é›† + æ—©åœé˜ˆå€¼
    'train_val_split': 0.9,            # 90%è®­ç»ƒ 10%éªŒè¯
    'early_stop_ppl': 20,              # PPL>20å³åœ
    'early_stop_patience': 3,          # ä¸‰æ¬¡ä¸é™å³åœ
    'eval_steps': 500,                 # æ¯500æ­¥è¯„ä¼°
    
    # ğŸƒ å¤„æ–¹5: è½»è°ƒå­¦ä¹ ç‡
    'learning_rate': 5e-4,             # 1e-4â†’5e-4 (cosine decay)
    'warmup_ratio': 0.05,              # çŸ­é¢„çƒ­å¿«é€Ÿåˆ°æœ€å¤§LR
    
    # ğŸƒ å¤„æ–¹6: æ­£åˆ™åŠ å‘³
    'attention_dropout': 0.1,          # æ³¨æ„åŠ›dropout
    'weight_decay': 0.01,              # æƒé‡è¡°å‡
    
    # ğŸƒ å¤„æ–¹2+3: ä¿®æ­£å¯¹é½ + ä¸¥æ ¼Mask
    'input_target_align': 'fixed',     # ä¿®å¤åŒé‡å¯¹é½é”™è¯¯
    'loss_reduction': 'sum_masked',    # ä¸¥æ ¼maskç¡®ä¿åˆ†æ¯>0
    
    # æ¨¡å‹é…ç½®
    'd_model': 512,
    'num_transformer_layers': 6,
    'num_rev_blocks': 3,
    'batch_size': 12,
    'max_epochs': 1                    # 300M tokensåªéœ€1è½®
}

# ğŸƒ é¢„æœŸæ²»ç–—æ•ˆæœ
# â”œâ”€â”€ éªŒè¯å›°æƒ‘åº¦: 2-8 (å¥åº·èŒƒå›´ï¼Œé¿å…1.0è¿‡æ‹Ÿåˆ)
# â”œâ”€â”€ argmaxå‡†ç¡®ç‡: >85% (ä¿®å¤å¯¹é½å)
# â”œâ”€â”€ æ–‡æœ¬ç”Ÿæˆ: è¿è´¯æœ‰æ„ä¹‰ï¼Œé¿å…èƒ¡è¨€ä¹±è¯­
# â””â”€â”€ è®­ç»ƒç¨³å®š: æ— å‰§çƒˆéœ‡è¡ï¼Œå¹³æ»‘æ”¶æ•›
```

#### ğŸ©º è®­ç»ƒé—®é¢˜è¯Šæ–­ä¸æ²»ç–—å†ç¨‹

**åŸå§‹ç—‡çŠ¶**: æ¨¡å‹å›°æƒ‘åº¦é™åˆ°1.0ä½†è¾“å‡ºèƒ¡è¨€ä¹±è¯­

**è¯Šæ–­è¿‡ç¨‹**:
1. **æ•°æ®æ³„æ¼æ£€æµ‹** âœ… å‘ç°52ä¸ªé‡å åºåˆ—ï¼ˆæ³„æ¼ç‡0.08%ï¼‰
2. **å¯¹é½é”™è¯¯è¯Šæ–­** âœ… å‘ç°åŒé‡å¯¹é½å¯¼è‡´é”™ä½  
3. **Maskè®¡ç®—æ£€æŸ¥** âœ… å‘ç°åˆ†æ¯å¯èƒ½ä¸º0çš„é£é™©
4. **è¿‡æ‹Ÿåˆç›‘æ§** âœ… ç¼ºä¹PPLé˜ˆå€¼æ—©åœæœºåˆ¶

**æ²»ç–—æ–¹æ¡ˆ**: 6æ¡åŒ»ç”Ÿå¤„æ–¹
- ğŸƒ **å¤„æ–¹1**: ç§»é™¤2,277ä¸ªé‡å åºåˆ—ï¼Œé‡åˆ‡90/10éªŒè¯é›†
- ğŸƒ **å¤„æ–¹2**: ä¿®å¤åŒé‡å¯¹é½ï¼Œç¡®ä¿`inputs[i] â†’ targets[i]`
- ğŸƒ **å¤„æ–¹3**: ä¸¥æ ¼Maskè®¡ç®—ï¼Œ`loss = sum(masked_loss)/mask_count`
- ğŸƒ **å¤„æ–¹4**: PPL>20æ—©åœï¼Œæ¯500æ­¥ç›‘æ§
- ğŸƒ **å¤„æ–¹5**: å­¦ä¹ ç‡5e-4ï¼Œcosine decayè°ƒåº¦
- ğŸƒ **å¤„æ–¹6**: dropout=0.1 + weight_decay=0.01æ­£åˆ™åŒ–

**åº·å¤æŒ‡æ ‡** (å·²éªŒè¯):
```
ğŸ” Step 0 å¯¹é½æ£€æŸ¥ (æ²»ç–—å):
â”œâ”€â”€ è¾“å…¥åºåˆ—: [101, 8024, 3221, 678, 6785]
â”œâ”€â”€ çœŸå®æ ‡ç­¾: [8024, 3221, 678, 6785, 4638]  âœ… å¯¹é½æ­£ç¡®
â”œâ”€â”€ åˆå§‹å‡†ç¡®ç‡: 0.0% (æ­£å¸¸ï¼Œéšæœºåˆå§‹åŒ–æƒé‡)
â”œâ”€â”€ é¢„æœŸå‡†ç¡®ç‡: è®­ç»ƒ500æ­¥å>85%
â””â”€â”€ ğŸ©º è¯Šæ–­: åŒé‡å¯¹é½é—®é¢˜å·²ä¿®å¤ï¼Œæ¨¡å‹å¯æ­£å¸¸å­¦ä¹ 
```

**ğŸ“‹ å¯¹é½éªŒè¯è¯´æ˜**:
- âœ… `inputs[0]=101` â†’ é¢„æµ‹ `targets[0]=8024` (ä¸‹ä¸€ä¸ªtoken)
- âœ… `inputs[1]=8024` â†’ é¢„æµ‹ `targets[1]=3221` (ä¸‹ä¸€ä¸ªtoken)  
- âœ… æ— é”™ä½ç°è±¡ï¼Œåºåˆ—é¢„æµ‹é€»è¾‘æ­£ç¡®
- âš ï¸ Step 0å‡†ç¡®ç‡0%å±æ­£å¸¸ç°è±¡ï¼ˆéšæœºæƒé‡ï¼‰
- ğŸ“ˆ éšè®­ç»ƒè¿›è¡Œï¼Œå‡†ç¡®ç‡å°†ç¨³æ­¥æå‡è‡³85%+

## ğŸ¯ è®­ç»ƒç›‘æ§

### å®æ—¶ç›‘æ§ç•Œé¢

```bash
python monitor.py
```

ç›‘æ§ç•Œé¢æ˜¾ç¤ºï¼š
- ğŸš€ è®­ç»ƒçŠ¶æ€ï¼šè¿è¡Œä¸­/å·²åœæ­¢
- ğŸ’» GPUä½¿ç”¨ç‡ï¼šåˆ©ç”¨ç‡ã€æ˜¾å­˜ã€æ¸©åº¦
- ğŸ’¾ æ£€æŸ¥ç‚¹çŠ¶æ€ï¼šæœ€æ–°æ¨¡å‹ã€ä¿å­˜æ—¶é—´
- ğŸ“Š æ¨¡å‹æ€§èƒ½ï¼šéªŒè¯æŸå¤±ã€å›°æƒ‘åº¦ã€è®­ç»ƒæ­¥æ•°

### é¢„æœŸè®­ç»ƒæŒ‡æ ‡

```
æ­£å¸¸è®­ç»ƒæŒ‡æ ‡:
â”œâ”€â”€ éªŒè¯å›°æƒ‘åº¦: 2.0 - 8.0 (å¥åº·èŒƒå›´)
â”œâ”€â”€ è®­ç»ƒæŸå¤±: ç¨³æ­¥ä¸‹é™ï¼Œä¸è¿‡å¿«
â”œâ”€â”€ GPUåˆ©ç”¨ç‡: 30-40% (5å¼ 4090)
â””â”€â”€ æ˜¾å­˜ä½¿ç”¨: ~3.2-3.5GB/GPU

âš ï¸ è¿‡æ‹Ÿåˆè­¦å‘Šä¿¡å·:
â”œâ”€â”€ éªŒè¯å›°æƒ‘åº¦æ¥è¿‘1.0
â”œâ”€â”€ éªŒè¯æŸå¤±æŒç»­ä¸‹é™è‡³æ¥è¿‘0
â””â”€â”€ ç”Ÿæˆæ–‡æœ¬é‡å¤æˆ–èƒ¡è¨€ä¹±è¯­
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ğŸ”¥ å½“å‰æ¶æ„ (å¯é€†1Ã—1å·ç§¯ç‰ˆæœ¬)
```
è¾“å…¥ (B,d)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plugboard P (ç¨€ç–åŒå°„å±‚)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dynamic InvertibleConv1x1       â”‚
â”‚ (Glowé£æ ¼å¯é€†1Ã—1å·ç§¯æ ˆ)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RevBlocks Nå±‚ (å¯é€†å·ç§¯å±‚)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reflector U (å¯¹ç§°æ­£äº¤å±‚)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RevBlocks^R (é€†åºå¯é€†å·ç§¯å±‚)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plugboard^T (è½¬ç½®ç¨€ç–å±‚)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
è¾“å‡º (B,d)
```

## æ ¸å¿ƒç»„ä»¶

### 1. ğŸ†• å¯é€†1Ã—1å·ç§¯ç³»ç»Ÿ

```python
from enigma.invertible_conv1x1 import DynamicInvertibleConv1x1Stack

# åŸºç¡€å¯é€†1Ã—1å·ç§¯å±‚
conv1x1 = InvertibleConv1x1(num_channels=768)

# å¤šå±‚å †æ ˆ 
conv1x1_stack = InvertibleConv1x1Stack(num_channels=768, num_layers=4)

# åŠ¨æ€ç‰ˆæœ¬ï¼ˆæ”¯æŒrotoræ­¥è¿›æœºåˆ¶ï¼‰
dynamic_conv1x1 = DynamicInvertibleConv1x1Stack(
    num_channels=768, 
    num_layers=4,
    positions=16  # æ­¥è¿›ä½ç½®æ•°
)
```

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- **LUåˆ†è§£**: W = PLUï¼Œå…¶ä¸­Pæ˜¯ç½®æ¢çŸ©é˜µï¼ŒLæ˜¯ä¸‹ä¸‰è§’ï¼ŒUæ˜¯ä¸Šä¸‰è§’
- **æ•°å€¼ç¨³å®š**: ç›´æ¥è®¡ç®—log|det(W)| = Î£log|U_ii|ï¼Œé¿å…è¡Œåˆ—å¼è®¡ç®—
- **å®Œå…¨å¯é€†**: W^(-1) = U^(-1)L^(-1)P^Tï¼Œç²¾ç¡®é€†å˜æ¢
- **rotoræœºåˆ¶**: æ”¯æŒåŠ¨æ€ä½ç½®æ­¥è¿›ï¼Œä¿æŒEnigmaæœºç‰¹æ€§

### 2. å‡çº§åçš„ä¸»è¦ç»„ä»¶

1. **Plugboard**ï¼šä¿æŒé«˜æ•ˆç´¢å¼•å®ç°
2. **DynamicConv1x1Stack**ï¼šæ›¿ä»£åŸå§‹RotorStackï¼Œæä¾›æ›´å¥½çš„å¯é€†æ€§
3. **RevBlock**ï¼šå¯é€†å·ç§¯å—ï¼Œè¯¯å·®â‰¤1e-8
4. **Reflector**ï¼šHouseholderåå°„å®ç°

## ğŸ® å¤šGPUè®­ç»ƒç³»ç»Ÿ

### ç¡¬ä»¶é…ç½®
- **GPU**: 5Ã—RTX 4090 (æ¯å¼ 47.4GBæ˜¾å­˜)
- **æ€»æ˜¾å­˜**: ~245GB
- **å¹¶è¡Œç­–ç•¥**: æ•°æ®åˆ†ç‰‡ + æ¨¡å‹å¹¶è¡Œ

### æ•°æ®åˆ†ç‰‡ç­–ç•¥

```
æ€»æ ·æœ¬: 1,192,999 (æ¸…ç†åæ— æ³„æ¼æ•°æ®)
â”œâ”€â”€ GPU 0: æ ·æœ¬ 0-238,599      (238,599ä¸ª)
â”œâ”€â”€ GPU 1: æ ·æœ¬ 238,599-477,198  (238,599ä¸ª) 
â”œâ”€â”€ GPU 2: æ ·æœ¬ 477,198-715,797  (238,599ä¸ª)
â”œâ”€â”€ GPU 3: æ ·æœ¬ 715,797-954,396  (238,599ä¸ª)
â””â”€â”€ GPU 4: æ ·æœ¬ 954,396-1,192,999 (238,603ä¸ª)
```

## ğŸ›  å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.9+ (æ”¯æŒCUDA)
- 5Ã—RTX 4090 GPU (æ¨è)
- 90GB+ ç³»ç»Ÿå†…å­˜

### å®‰è£…

```bash
git clone https://github.com/your-repo/Enigma.git
cd Enigma
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

### ğŸ“ æ•°æ®å‡†å¤‡ (DIY)

**ç”¨æˆ·éœ€è¦è‡ªè¡Œå‡†å¤‡ä»¥ä¸‹æ•°æ®**ï¼š

1. **ä¸­æ–‡æ–‡æœ¬æ•°æ®é›†**:
   ```bash
   # æ•°æ®æ ¼å¼è¦æ±‚
   wiki-full-zh/processed/
   â”œâ”€â”€ train_seq256_bert_fast.pt    # è®­ç»ƒé›† (å¿…éœ€)
   â”œâ”€â”€ val_seq256_bert_fast.pt      # éªŒè¯é›† (å¿…éœ€)
   â””â”€â”€ test_seq256_bert_fast.pt     # æµ‹è¯•é›† (å¯é€‰)
   ```

2. **BERTä¸­æ–‡ç¼–ç å™¨**:
   ```bash
   # ä¸‹è½½BERTæ¨¡å‹åˆ°æŒ‡å®šç›®å½•
   bert-chinese-base/
   â”œâ”€â”€ config.json              # BERTé…ç½®æ–‡ä»¶
   â”œâ”€â”€ pytorch_model.bin        # é¢„è®­ç»ƒæƒé‡
   â”œâ”€â”€ tokenizer_config.json    # åˆ†è¯å™¨é…ç½®
   â””â”€â”€ vocab.txt               # è¯æ±‡è¡¨æ–‡ä»¶
   
   # æ¨èä¸‹è½½åœ°å€:
   # https://huggingface.co/bert-base-chinese
   # https://huggingface.co/hfl/chinese-bert-wwm-ext
   ```

3. **æ•°æ®æ ¼å¼è¦æ±‚**:
   - æ¯ä¸ª`.pt`æ–‡ä»¶åŒ…å«tokenizedçš„åºåˆ—æ•°æ®
   - åºåˆ—é•¿åº¦: 256 tokens
   - vocab_size: 21128 (BERTä¸­æ–‡è¯æ±‡è¡¨)

### ğŸš€ å¯åŠ¨ä¼˜åŒ–è®­ç»ƒ

```bash
# ğŸ”¥ å¤šGPUè®­ç»ƒ (æ¨èï¼Œå·²ä¼˜åŒ–)
python scripts/train_multi_gpu_simple.py

# ğŸ”¥ å•GPUè®­ç»ƒ (å·²ä¼˜åŒ–)  
python scripts/train_single_gpu_simple.py

# è®­ç»ƒç‰¹æ€§:
# âœ… æ—©åœæœºåˆ¶: è¿ç»­2è½®éªŒè¯ä¸é™å³åœ
# âœ… æ™ºèƒ½ä¿å­˜: æ¯2kæ­¥éªŒè¯ + 10kæ­¥ä¿å­˜
# âœ… å›°æƒ‘åº¦ç›‘æ§: å®æ—¶æ˜¾ç¤ºlosså’Œperplexity
# âœ… æ¿€æ´»æ£€æŸ¥ç‚¹: èŠ‚çœ20-30%æ˜¾å­˜
# âœ… BERTè¯æ±‡è¡¨: ç»Ÿä¸€ä½¿ç”¨ä¸­æ–‡BERT tokenizer
```

### ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# æŸ¥çœ‹æœ€æ–°è®­ç»ƒæ£€æŸ¥ç‚¹
ls checkpoints_*_optimized/

# å®æ—¶ç›‘æ§è®­ç»ƒæ—¥å¿—
tail -f nohup.out

# æŸ¥çœ‹æœ€ä½³æ¨¡å‹æ€§èƒ½
python -c "
import torch
ckpt = torch.load('checkpoints_multigpu_simple_512d_optimized/best_model_multigpu_simple.pt')
print(f'æœ€ä½³éªŒè¯æŸå¤±: {ckpt["val_loss"]:.4f}')
print(f'å›°æƒ‘åº¦: {torch.exp(torch.tensor(ckpt["val_loss"])):.2f}')
print(f'è®­ç»ƒæ­¥æ•°: {ckpt["global_step"]}')
"
```

## ğŸ”§ æ¨¡å‹ä½¿ç”¨

### åˆ›å»ºæ¨¡å‹

```python
from enigma.model import EnigmaLM

# ä½¿ç”¨å¯é€†1Ã—1å·ç§¯çš„æ¨¡å‹
model = EnigmaLM(
    vocab_size=21128,
    d=768,
    num_rev_blocks=6,
    num_rotors=4,
    num_transformer_layers=12,
    num_heads=12,
    max_len=2048,
    use_alibi=True,
    use_dynamic_conv1x1=True,    # ğŸ†• ä½¿ç”¨åŠ¨æ€å¯é€†1Ã—1å·ç§¯
    conv1x1_positions=16
)

print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
# è¾“å‡º: æ¨¡å‹å‚æ•°: 148,853,010
```

### æ¨ç†ä½¿ç”¨

```python
import torch

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
checkpoint = torch.load('checkpoints_multigpu/best_model_multigpu.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# æ–‡æœ¬ç”Ÿæˆ
input_ids = torch.randint(0, 21128, (1, 10))
with torch.no_grad():
    output = model(input_ids)
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")  # [1, 10, 21128]
```

## ğŸ§ª æ‰©å±•åŠŸèƒ½

### Flowç”Ÿæˆæ¨¡å‹

```python
from enigma.jacobian_logdet import EnigmaFlow

# åˆ›å»ºFlowæ¨¡å‹
enigma_model = Enigma(d=64, num_rev_blocks=3, num_rotors=3)
flow_model = EnigmaFlow(enigma_model, prior='gaussian')

# è®¡ç®—å¯¹æ•°æ¦‚ç‡
samples = torch.randn(10, 64)
log_probs = flow_model.log_prob(samples)

# é‡‡æ ·ç”Ÿæˆ
generated = flow_model.sample(num_samples=10)
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ğŸ”¥ æœ€æ–°ä¼˜åŒ–æ•ˆæœ (2025-05-23)

| æŒ‡æ ‡ | æ—§é…ç½® | ğŸ”¥ æ–°é…ç½® | æå‡ |
|------|--------|----------|------|
| **æ¨¡å‹å‚æ•°** | 148M | **~90M** | **å‡å°‘39%** |
| **Transformerå±‚** | 12å±‚ | **8å±‚** | **å‡å°‘33%** |
| **è®­ç»ƒé€Ÿåº¦** | åŸºå‡† | **+30-40%** | **æ˜¾è‘—æå‡** |
| **æ˜¾å­˜ä½¿ç”¨** | 8GB/GPU | **6-8GB/GPU** | **èŠ‚çœ20%** |
| **æ‰¹å¤§å°** | 320 | **160** | **æ›´é«˜æ•ˆ** |
| **å­¦ä¹ ç‡** | 2e-4 | **5e-4** | **æ”¶æ•›æ›´å¿«** |

### å¯é€†æ€§ç²¾åº¦

| ç‰ˆæœ¬ | é‡æ„è¯¯å·® | æ•°å€¼ç¨³å®šæ€§ | è®­ç»ƒé€Ÿåº¦ | ä»£ç å¤æ‚åº¦ |
|------|----------|------------|----------|------------|
| Sinkhornç‰ˆæœ¬ | ~1e-4 | ä¸­ç­‰ | è¾ƒæ…¢ | å¤æ‚ |
| **å¯é€†1Ã—1å·ç§¯ç‰ˆæœ¬** | **~1e-6** | **é«˜** | **å¿«** | **ç®€æ´** |

### å¤šGPUè®­ç»ƒæ•ˆæœ

| é…ç½® | è®­ç»ƒæ—¶é—´/epoch | GPUåˆ©ç”¨ç‡ | æ˜¾å­˜ä½¿ç”¨ | æœ‰æ•ˆæ‰¹å¤§å° |
|------|----------------|-----------|----------|------------|
| å•GPU (æ—§) | ~2å°æ—¶ | 85% | 45GB | 128 |
| å•GPU (ğŸ”¥æ–°) | **~1.2å°æ—¶** | **80%** | **6-8GB** | **128** |
| **5Ã—GPU (ğŸ”¥æ–°)** | **~15åˆ†é’Ÿ** | **60%** | **6-8GBÃ—5** | **160** |

## ğŸ”„ ä¼˜åŒ–å†ç¨‹

### é˜¶æ®µ1: Sinkhornç®—æ³•æ—¶æœŸ
- ä½¿ç”¨Gumbel-Sinkhornç®—æ³•å®ç°åŠ¨æ€ç½®æ¢
- æ¸©åº¦é€€ç«ç­–ç•¥ä¿è¯å¯å¾®æ€§
- å­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜

### é˜¶æ®µ2: å¯é€†1Ã—1å·ç§¯å‡çº§  
- **æ›¿æ¢**: Sinkhorn â†’ Glowé£æ ¼å¯é€†1Ã—1å·ç§¯
- **ä¼˜åŠ¿**: æ›´é«˜ç²¾åº¦ã€æ›´å¥½æ¢¯åº¦æµã€æ›´ç®€å•å®ç°
- **ç»“æœ**: é‡æ„è¯¯å·®ä»1e-4æå‡åˆ°1e-6

### é˜¶æ®µ3: å¤šGPUå¹¶è¡Œç³»ç»Ÿ
- **å®ç°**: 5å¼ 4090 GPU DistributedDataParallelè®­ç»ƒ
- **ä¼˜åŒ–**: æ•°æ®åˆ†ç‰‡ã€åŠ¨æ€ä¼ è¾“ã€æ··åˆç²¾åº¦
- **æ•ˆæœ**: è®­ç»ƒé€Ÿåº¦æå‡5å€ï¼Œèµ„æºåˆ©ç”¨æœ€å¤§åŒ–

### é˜¶æ®µ4: ğŸ”¥ æ·±åº¦é…ç½®ä¼˜åŒ– (2025-05-23)
- **æ¨¡å‹ç²¾ç®€**: 12å±‚â†’8å±‚ï¼Œ6å—â†’4å—ï¼Œ4è½¬â†’2è½¬
- **è®­ç»ƒæ™ºèƒ½åŒ–**: æ—©åœã€æ¿€æ´»æ£€æŸ¥ç‚¹ã€å›°æƒ‘åº¦ç›‘æ§
- **ä»£ç ç°ä»£åŒ–**: BERTè¯æ±‡è¡¨ã€æ¸…ç†å†—ä½™ã€ç»Ÿä¸€æ¥å£  
- **æ•ˆæœ**: å‚æ•°å‡å°‘39%ï¼Œè®­ç»ƒé€Ÿåº¦æå‡40%ï¼Œä»£ç ç²¾ç®€1400è¡Œ

## ğŸš¦ é¡¹ç›®çŠ¶æ€

- âœ… **æ ¸å¿ƒæ¶æ„**: å®Œæˆï¼Œå¯é€†1Ã—1å·ç§¯ç‰ˆæœ¬
- âœ… **å¤šGPUè®­ç»ƒ**: å®Œæˆï¼Œ5Ã—4090å¹¶è¡Œè®­ç»ƒ
- âœ… **æ•°å€¼ç¨³å®šæ€§**: ä¼˜åŒ–å®Œæˆï¼Œè¯¯å·®â‰¤1e-6
- âœ… **æ‰©å±•åŠŸèƒ½**: Flowæ¨¡å‹
- âœ… **ğŸ”¥ é…ç½®ä¼˜åŒ–**: å®Œæˆï¼Œæ¨¡å‹ç²¾ç®€+è®­ç»ƒæ™ºèƒ½åŒ–
- âœ… **ğŸ”¥ BERTè¿ç§»**: å®Œæˆï¼Œç»Ÿä¸€è¯æ±‡è¡¨
- âœ… **ğŸ”¥ ä»£ç ç°ä»£åŒ–**: å®Œæˆï¼Œç²¾ç®€1400+è¡Œ
- ğŸ”„ **å½“å‰**: ä½¿ç”¨æœ€æ–°ä¼˜åŒ–é…ç½®è®­ç»ƒä¸­
- ğŸ¯ **ä¸‹ä¸€æ­¥**: è¯„ä¼°ä¼˜åŒ–æ•ˆæœï¼Œå‡†å¤‡ç”Ÿäº§éƒ¨ç½²

### ğŸ¯ å½“å‰è®­ç»ƒçŠ¶æ€
```bash
# ğŸš€ ç®€åŒ–å¯åŠ¨ (æ¨è)
python train.py              # ä¸€é”®å¯åŠ¨é˜²è¿‡æ‹Ÿåˆè®­ç»ƒ
python monitor.py            # å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦

# ğŸ”§ ç›´æ¥è°ƒç”¨è®­ç»ƒè„šæœ¬
python scripts/train.py      # æ ¸å¿ƒé˜²è¿‡æ‹Ÿåˆè®­ç»ƒè„šæœ¬

# ç‰¹æ€§: 6å±‚Transformer + 4å¯é€†å— + é˜²è¿‡æ‹Ÿåˆé…ç½®
# é¢„æœŸ: éªŒè¯å›°æƒ‘åº¦2-8ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼Œç”Ÿæˆè¿è´¯æ–‡æœ¬
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
Enigma/
â”œâ”€â”€ ğŸš€ train.py                         # ğŸ†• ç®€åŒ–è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ ğŸ“Š monitor.py                       # ğŸ†• å®æ—¶è®­ç»ƒç›‘æ§å·¥å…·
â”œâ”€â”€ enigma/                             # ğŸ”§ æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ model.py                        # ä¸»æ¨¡å‹å®šä¹‰ (é˜²è¿‡æ‹Ÿåˆä¼˜åŒ–)
â”‚   â”œâ”€â”€ invertible_conv1x1.py           # ğŸ†• å¯é€†1Ã—1å·ç§¯å®ç°
â”‚   â”œâ”€â”€ simple_permutation.py           # ğŸ†• ç®€åŒ–ç½®æ¢å±‚
â”‚   â”œâ”€â”€ jacobian_logdet.py              # Flowæ¨¡å‹æ”¯æŒ
â”‚   â”œâ”€â”€ attention.py                    # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ token_embedding.py              # TokenåµŒå…¥å±‚
â”‚   â”œâ”€â”€ plugboard.py                    # Plugboardç»„ä»¶
â”‚   â”œâ”€â”€ rotor.py                        # Rotorè½¬å­ç»„ä»¶
â”‚   â”œâ”€â”€ rotor_base.py                   # è½¬å­åŸºç±»
â”‚   â”œâ”€â”€ rev_block.py                    # å¯é€†å—
â”‚   â””â”€â”€ reflector.py                    # åå°„å™¨
â”œâ”€â”€ scripts/                            # ğŸš€ è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ train.py                        # ğŸ”¥ é˜²è¿‡æ‹Ÿåˆå¤šGPUè®­ç»ƒ (ä¸»è¦è„šæœ¬)
â”œâ”€â”€ wiki-full-zh/                       # ğŸ“Š æ•°æ®é›† (ç”¨æˆ·è‡ªå¤‡)
â”‚   â”œâ”€â”€ processed/                      # å¤„ç†åæ•°æ®
â”‚   â”‚   â”œâ”€â”€ train_seq256_bert_fast.pt   # ğŸ”¥ è®­ç»ƒæ•°æ® (1,192,999æ ·æœ¬ï¼Œæ— æ³„æ¼)
â”‚   â”‚   â”œâ”€â”€ val_seq256_bert_fast.pt     # ğŸ”¥ éªŒè¯æ•°æ®
â”‚   â”‚   â”œâ”€â”€ test_seq256_bert_fast.pt    # ğŸ”¥ æµ‹è¯•æ•°æ®
â”‚   â”‚   â””â”€â”€ backup/                     # æ•°æ®å¤‡ä»½ç›®å½•
â”‚   â””â”€â”€ train-*.parquet                 # åŸå§‹æ•°æ®æ–‡ä»¶ (6ä¸ªåˆ†ç‰‡)
â”œâ”€â”€ bert-chinese-base/                  # ğŸ¤– BERTç¼–ç å™¨ (ç”¨æˆ·è‡ªå¤‡)
â”‚   â”œâ”€â”€ config.json                     # BERTé…ç½®
â”‚   â”œâ”€â”€ pytorch_model.bin               # é¢„è®­ç»ƒæƒé‡
â”‚   â”œâ”€â”€ tokenizer_config.json           # åˆ†è¯å™¨é…ç½®
â”‚   â””â”€â”€ vocab.txt                       # è¯æ±‡è¡¨ (21128ä¸ªè¯)
â”œâ”€â”€ checkpoints_anti_overfitting/       # ğŸ¯ å½“å‰è®­ç»ƒæ£€æŸ¥ç‚¹
â”œâ”€â”€ checkpoints_backup/                 # ğŸ—‚ï¸ æ—§æ¨¡å‹å¤‡ä»½
â”œâ”€â”€ checkpoints_multigpu_simple_512d_optimized/ # ğŸ† å†å²æœ€ä½³æ¨¡å‹
â”œâ”€â”€ tests/                              # ğŸ§ª å•å…ƒæµ‹è¯•
â”œâ”€â”€ README.md                           # ğŸ“š é¡¹ç›®æ–‡æ¡£ (æœ¬æ–‡ä»¶)
â”œâ”€â”€ LICENSE                             # ğŸ“„ MITè®¸å¯è¯
â””â”€â”€ .gitignore                          # ğŸš« Gitå¿½ç•¥æ–‡ä»¶

# ğŸ¯ ç®€åŒ–çš„å¯åŠ¨æ–¹å¼
# â”œâ”€â”€ python train.py          # ğŸš€ ä¸€é”®å¯åŠ¨é˜²è¿‡æ‹Ÿåˆè®­ç»ƒ
# â”œâ”€â”€ python monitor.py        # ğŸ“Š å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦
# â””â”€â”€ python scripts/train.py  # ğŸ”§ ç›´æ¥è°ƒç”¨æ ¸å¿ƒè®­ç»ƒè„šæœ¬
```

### ğŸ”¥ æœ€æ–°æ–‡ä»¶è¯´æ˜

**å¯åŠ¨è„šæœ¬**:
- `train.py`: ğŸ†• æ ¹ç›®å½•ç®€åŒ–å¯åŠ¨è„šæœ¬ï¼Œä¸€é”®å¼€å§‹è®­ç»ƒ
- `monitor.py`: ğŸ†• å®æ—¶è®­ç»ƒç›‘æ§å·¥å…·ï¼ŒGPUçŠ¶æ€+æ¨¡å‹æ€§èƒ½

**æ ¸å¿ƒè®­ç»ƒè„šæœ¬**:
- `scripts/train.py`: ğŸ”¥ é˜²è¿‡æ‹Ÿåˆå¤šGPUè®­ç»ƒä¸»è„šæœ¬ (åŸtrain_anti_overfitting.py)

**æ¨¡å‹ç»„ä»¶**:
- `model.py`: é˜²è¿‡æ‹Ÿåˆä¼˜åŒ–æ¨¡å‹ (6å±‚Transformer+4å¯é€†å—)
- `invertible_conv1x1.py`: Glowé£æ ¼å¯é€†1Ã—1å·ç§¯ (æ›¿ä»£Sinkhorn)
- `simple_permutation.py`: ç®€åŒ–ç½®æ¢å®ç°
- `jacobian_logdet.py`: Flowæ¨¡å‹æ”¯æŒ

**æ•°æ®å¤„ç†**:
- è®­ç»ƒæ•°æ®ï¼š1,192,999æ ·æœ¬ (å·²ä¿®å¤æ•°æ®æ³„æ¼)
- ç»Ÿä¸€ä½¿ç”¨BERTä¸­æ–‡è¯æ±‡è¡¨ (vocab_size=21128)
- åºåˆ—é•¿åº¦256ï¼Œæ”¯æŒé˜²è¿‡æ‹Ÿåˆè®­ç»ƒ

**æ£€æŸ¥ç‚¹ç®¡ç†**:
- `checkpoints_anti_overfitting/`: å½“å‰é˜²è¿‡æ‹Ÿåˆè®­ç»ƒæ£€æŸ¥ç‚¹
- `checkpoints_backup/`: æ—§æ¨¡å‹å¤‡ä»½ç›®å½•
- æ™ºèƒ½ä¿å­˜ç­–ç•¥: éªŒè¯æŸå¤±æœ€ä½³æ¨¡å‹è‡ªåŠ¨ä¿å­˜

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Glow**: Kingma & Dhariwal. "Glow: Generative Flow using Invertible 1x1 Convolutions"
2. **RevNets**: Gomez et al. "The Reversible Residual Network"
3. **ALiBi**: Press et al. "Train Short, Test Long: Attention with Linear Biases"
4. **DDP**: PyTorch Distributed Data Parallel

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

> **ğŸ”¥ æœ€æ–°è®­ç»ƒçŠ¶æ€ (2025-05-23)**: 
> 
> ğŸš€ **å·²éƒ¨ç½²æœ€æ–°ä¼˜åŒ–é…ç½®**ï¼š8å±‚Transformer + 4å¯é€†å— + 2è½¬å­ + æ™ºèƒ½è®­ç»ƒç­–ç•¥
> 
> âš¡ **æ€§èƒ½æå‡**ï¼šå‚æ•°å‡å°‘39%ï¼Œè®­ç»ƒé€Ÿåº¦æå‡40%ï¼Œæ˜¾å­˜èŠ‚çœ20%
> 
> ğŸ¯ **æŠ€æœ¯ç‰¹æ€§**ï¼šæ—©åœæœºåˆ¶ + æ¿€æ´»æ£€æŸ¥ç‚¹ + å›°æƒ‘åº¦ç›‘æ§ + BERTè¯æ±‡è¡¨
> 
> ğŸ“Š **è®­ç»ƒé…ç½®**ï¼š`effective_batch=160`, `lr=5e-4`, `eval_every=2k_steps`
> 
> ğŸ’¾ **æ£€æŸ¥ç‚¹è·¯å¾„**ï¼š`checkpoints_*_optimized/` (æ™ºèƒ½ä¿å­˜ç­–ç•¥)
> 
> ğŸ® **å¯åŠ¨å‘½ä»¤**ï¼š`python train.py` (æ¨è) æˆ– `python scripts/train.py` (ç›´æ¥è°ƒç”¨)
